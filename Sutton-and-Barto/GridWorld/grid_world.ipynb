{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d7faabe-91a4-4b06-9d4e-dffac9acd399",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1d16d6cd-2a0e-4a59-a97c-9ad9433e7526",
   "metadata": {},
   "outputs": [],
   "source": [
    "UP  = 0\n",
    "DOWN = 1\n",
    "RIGHT = 2\n",
    "LEFT = 3\n",
    "\n",
    "def create_grid_world(size=4):\n",
    "    def get_next(s,direction):\n",
    "        if s == 0:\n",
    "            return 0\n",
    "        if direction == UP:\n",
    "            return s - size if s >= size else s\n",
    "        if direction == DOWN:\n",
    "            return (s + size) % (size * size - 1) if s < size * (size - 1) else s\n",
    "        if direction == RIGHT:\n",
    "            return (s + 1) % (size * size - 1) if ((s + 1) % size) != 0  else s\n",
    "        if direction == LEFT: \n",
    "            return s - 1 if (s % size) != 0 else s\n",
    "            \n",
    "    \n",
    "    states = list(range(size*size - 1))\n",
    "    actions = [UP,DOWN,RIGHT, LEFT]\n",
    "    rewards = [-1]\n",
    "\n",
    "    dynamic = {}\n",
    "    for state in states:\n",
    "        dynamic[state] = {}\n",
    "        for action in actions:\n",
    "            next_state = get_next(state, action)\n",
    "            dynamic[state][action] = [(1,(next_state, -1 if state != 0 else 0))]\n",
    "        \n",
    "    return states, actions, rewards, dynamic\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b7d8b316-b9cf-417f-b078-bf7aa868260c",
   "metadata": {},
   "outputs": [],
   "source": [
    "states, actions,rewards, dynamic = create_grid_world()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a1241c9b-3aa5-4b7e-83b9-32ef3647057c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {0: [(1, (0, 0))], 1: [(1, (0, 0))], 2: [(1, (0, 0))], 3: [(1, (0, 0))]},\n",
       " 1: {0: [(1, (1, -1))],\n",
       "  1: [(1, (5, -1))],\n",
       "  2: [(1, (2, -1))],\n",
       "  3: [(1, (0, -1))]},\n",
       " 2: {0: [(1, (2, -1))],\n",
       "  1: [(1, (6, -1))],\n",
       "  2: [(1, (3, -1))],\n",
       "  3: [(1, (1, -1))]},\n",
       " 3: {0: [(1, (3, -1))],\n",
       "  1: [(1, (7, -1))],\n",
       "  2: [(1, (3, -1))],\n",
       "  3: [(1, (2, -1))]},\n",
       " 4: {0: [(1, (0, -1))],\n",
       "  1: [(1, (8, -1))],\n",
       "  2: [(1, (5, -1))],\n",
       "  3: [(1, (4, -1))]},\n",
       " 5: {0: [(1, (1, -1))],\n",
       "  1: [(1, (9, -1))],\n",
       "  2: [(1, (6, -1))],\n",
       "  3: [(1, (4, -1))]},\n",
       " 6: {0: [(1, (2, -1))],\n",
       "  1: [(1, (10, -1))],\n",
       "  2: [(1, (7, -1))],\n",
       "  3: [(1, (5, -1))]},\n",
       " 7: {0: [(1, (3, -1))],\n",
       "  1: [(1, (11, -1))],\n",
       "  2: [(1, (7, -1))],\n",
       "  3: [(1, (6, -1))]},\n",
       " 8: {0: [(1, (4, -1))],\n",
       "  1: [(1, (12, -1))],\n",
       "  2: [(1, (9, -1))],\n",
       "  3: [(1, (8, -1))]},\n",
       " 9: {0: [(1, (5, -1))],\n",
       "  1: [(1, (13, -1))],\n",
       "  2: [(1, (10, -1))],\n",
       "  3: [(1, (8, -1))]},\n",
       " 10: {0: [(1, (6, -1))],\n",
       "  1: [(1, (14, -1))],\n",
       "  2: [(1, (11, -1))],\n",
       "  3: [(1, (9, -1))]},\n",
       " 11: {0: [(1, (7, -1))],\n",
       "  1: [(1, (0, -1))],\n",
       "  2: [(1, (11, -1))],\n",
       "  3: [(1, (10, -1))]},\n",
       " 12: {0: [(1, (8, -1))],\n",
       "  1: [(1, (12, -1))],\n",
       "  2: [(1, (13, -1))],\n",
       "  3: [(1, (12, -1))]},\n",
       " 13: {0: [(1, (9, -1))],\n",
       "  1: [(1, (13, -1))],\n",
       "  2: [(1, (14, -1))],\n",
       "  3: [(1, (12, -1))]},\n",
       " 14: {0: [(1, (10, -1))],\n",
       "  1: [(1, (14, -1))],\n",
       "  2: [(1, (0, -1))],\n",
       "  3: [(1, (13, -1))]}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dynamic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "44cc4de8-862d-44bb-b9d8-e0a5aac1afab",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_policy = {\n",
    "    state: [0.25,0.25,0.25,0.25] for state in states}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "287e071c-2f6f-4767-9744-113b25180691",
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_evaluation(states, policy, dynamic, actions, theta, discount =  1, max_iter = 100, V_init = None):\n",
    "    if V_init is None:\n",
    "        V = np.zeros(len(states))\n",
    "    else: \n",
    "        V = V_init[:]\n",
    "        \n",
    "    delta = 0\n",
    "    k = 0\n",
    "    while k < max_iter:\n",
    "        for state in states:\n",
    "            if state != 0:\n",
    "                v  = V[state]\n",
    "                partial_action = 0\n",
    "                for action in actions:\n",
    "                    p_action = policy[state][action]\n",
    "                    transitions = dynamic[state][action]\n",
    "                    partial_transitions = 0\n",
    "                    for transition in transitions:\n",
    "                        p_transition, (next_state, reward) = transition\n",
    "                        partial_transitions += p_transition *  (reward + discount * V[next_state])\n",
    "                    partial_action += p_action * partial_transitions\n",
    "                V[state] = partial_action\n",
    "\n",
    "                delta = max(delta, abs(v - V[state])) \n",
    "\n",
    "        if delta < theta:\n",
    "            return V\n",
    "        k += 1\n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a910bad7-7dd8-4d92-81dd-17ee6ce00652",
   "metadata": {},
   "outputs": [],
   "source": [
    "V = policy_evaluation(states, random_policy,dynamic, actions, 1,1, max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "bbdb951b-0123-4d34-9641-37bf037857c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_policy(states, actions, policy, dynamic, discount):\n",
    "    V = policy_evaluation(states, policy,dynamic, actions, 0.5,discount, max_iter=1000)\n",
    "\n",
    "    greedy = {0: [1] + [0] * (len(actions) - 1)}\n",
    "    for state in states : \n",
    "        if state != 0:\n",
    "            best_action  = actions[0]\n",
    "            transitions = dynamic[state][best_action]\n",
    "            best_q = 0\n",
    "            greedy[state] = [0] * len(actions)\n",
    "            for transition in transitions:\n",
    "                p_transition, (next_state, reward) = transition\n",
    "                best_q += p_transition *  (reward + discount * V[next_state])\n",
    "\n",
    "            for action in actions[1:]:\n",
    "                q = 0\n",
    "                transitions = dynamic[state][action]\n",
    "                for transition in transitions:\n",
    "                    p_transition, (next_state, reward) = transition\n",
    "                    q += p_transition *  (reward + discount * V[next_state])\n",
    "                if q > best_q:\n",
    "                    best_action = action\n",
    "                    best_q = q\n",
    "            greedy[state][best_action] = 1\n",
    "\n",
    "    return greedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c24685cf-464b-4508-b7e0-311a814820f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "greedy = greedy_policy(states, actions, random_policy, dynamic,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9c41a27a-dd3c-4ba1-b7d0-681b2c530060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0., -14., -20., -22., -14., -18., -20., -20., -20., -20., -18.,\n",
       "       -14., -22., -20., -14.])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "118e48a0-928c-41cc-8746-e3f7afec4760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [1, 0, 0, 0],\n",
       " 1: [0, 0, 0, 1],\n",
       " 2: [0, 0, 0, 1],\n",
       " 3: [0, 1, 0, 0],\n",
       " 4: [1, 0, 0, 0],\n",
       " 5: [0, 0, 0, 1],\n",
       " 6: [0, 1, 0, 0],\n",
       " 7: [0, 1, 0, 0],\n",
       " 8: [1, 0, 0, 0],\n",
       " 9: [1, 0, 0, 0],\n",
       " 10: [0, 0, 1, 0],\n",
       " 11: [0, 1, 0, 0],\n",
       " 12: [1, 0, 0, 0],\n",
       " 13: [0, 0, 1, 0],\n",
       " 14: [0, 0, 1, 0]}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "greedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e8d169f3-d535-41cf-a997-622f4c8e0958",
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_iteration(states, actions, dynamic, discount = 1, V_init=None, max_iter = 100):\n",
    "    # Initialization \n",
    "    if V_init is None:\n",
    "        V = np.zeros(len(states))\n",
    "    else:\n",
    "        V = V_init[:]\n",
    "\n",
    "    policy = {s : [1] + [0] * (len(actions) - 1) for s in states}\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        # policy evaluation \n",
    "        V = policy_evaluation(states, policy, dynamic, actions, 0.1,discount, V_init=V)\n",
    "    \n",
    "        # policy improvement\n",
    "        stable = True\n",
    "        new_policy = greedy_policy(states, actions, policy, dynamic, discount)\n",
    "        for state in states:\n",
    "            old_action = np.argmax(policy[state])\n",
    "            new_action = np.argmax(new_policy[state])\n",
    "            if old_action != new_action:\n",
    "                stable = False\n",
    "                break\n",
    "        if stable:\n",
    "            return new_policy\n",
    "        policy = new_policy\n",
    "    return policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "dcd00ed5-80d3-4882-9a2f-71bbab8b7e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = policy_iteration(states, actions, dynamic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "12721449-9aee-4b3e-8214-5bb23eccd004",
   "metadata": {},
   "outputs": [],
   "source": [
    "V = policy_evaluation(states, policy,dynamic, actions, 1,1, max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "64526038-0644-49b2-baf3-738a43dbcebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0., -1., -2., -3., -1., -2., -3., -2., -2., -3., -2., -1., -3.,\n",
       "       -2., -1.])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (GenerativeAI)",
   "language": "python",
   "name": "generativeai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
